{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SRCNN Using Theano\n",
    "\n",
    "This is a notebook on theano based Image-super resolution based on this [paper](https://arxiv.org/abs/1501.00092).\n",
    "This implementation is based on the implementation of ['corochann'](https://github.com/corochann).\n",
    "The original codes of this implementation can be found [here](https://github.com/corochann/theanonSR) \n",
    "\n",
    "## Introduction to Image Super_resolution\n",
    "\n",
    "Single image super-resolution (SR), which aims at recovering a high-resolution image from a single low-resolution image, is a classical problem in computer vision. This problem is inherently ill-posed since a multiplicity of solutions exist for any given low-resolution pixel.\n",
    "\n",
    "Such a problem is typically mitigated by constraining the solution space by strong prior information. To learn the prior,recent state-of-the-art methods mostly adopt example-based strategy. These methods either exploit internal similarities of the same image or learn mappingfunctions from external low- and high-resolution exemplar pairs.\n",
    "\n",
    "In this paper a Deep Convolutional Neural Network has been developed to solve this problem.The proposed Super-Resolution-convoluted-neural-network, SRCNN, has several appealing properties. First, its structure is intentionally designed with simplicity in mind, and yet provides superior accuracy.Secondly, with morderate numbers of filters and layers, this method achieves fast speed for practical on-line usage even on a CPU.\n",
    "\n",
    "## The model\n",
    "\n",
    "Consider a single low-resolution image, we first upscale it to the desired size using bicubic interpolation, which is the only pre-processing we perform. Let us denote the interpolated image as $Y$. Our goal is to recover from $Y$ an image $F(Y)$ that is as similaras possible to the ground truth high-resolution image $X$. For the ease of presentation, we still call $Y$ a “low-resolution” image, although it has the same size as $X$. We wish to learn a mapping $F$, which conceptually consists of three operations: \n",
    "\n",
    "1) <b>Patch extraction and representation:</b> this operation extracts (overlapping) patches from the low-resolution image $Y$ and represents each patch as a high-dimensional vector. These vectors comprise a set of feature maps, of which the number equals to the dimensionality of the vectors. \n",
    "\n",
    "2) <b>Non-linear mapping:</b> this operation nonlinearly maps each high-dimensional vector onto another high-dimensional vector. Each mapped vector is conceptually the representation of a high-resolution patch. These vectors comprise another set of feature maps. \n",
    "\n",
    "3) <b>Reconstruction:</b> this operation aggregates the above high-resolution patch-wise representations to generate the final high-resolution image. This image is expected to be similar to the ground truth $X$. \n",
    "\n",
    "\n",
    "\n",
    "![model image](model.png)\n",
    "\n",
    "\n",
    "This can be mathematically be represented as\n",
    "\n",
    "1) \n",
    "\\begin{equation}\n",
    "F_1 (Y) = max(0,W_1*Y +B_1)\n",
    "\\end{equation}\n",
    "where $W_1$ and $B_1$ represent the filters and biases respectively, and ’*’ denotes the convolution operation. Here,$ W_1$ corresponds to $n_1$ filters of support $c\\times f_1 \\times f_1$, where $c$ is the number of channels in the input image, $f_1$ is the spatial size of a filter.\n",
    "\n",
    "2) \n",
    "\\begin{equation}\n",
    "F_2 (Y) = max(0,W_2*F_1(Y) +B_2)\n",
    "\\end{equation}\n",
    "Here, $W_2$ contains $n_2$ filters of size $n_1\\times f_2 \\times f_2$, and $B_2$ is $n_2$-dimensional.\n",
    "\n",
    "3) \n",
    "\\begin{equation}\n",
    "F(Y) = W_3*F_2(Y) +B_3\n",
    "\\end{equation}\n",
    "Here $W_3$ corresponds to $c$ filters of a size $n_2 \\times f_3\\times f_3$, and $B_3$ is a $c$-dimensional vector.\n",
    "\n",
    "## Training\n",
    "\n",
    "Learning the end-to-end mapping function $F$ requires the estimation of network parameters $\\Theta = \\{ W_1;W_2;W_3;B_1;B_2;B_3\\} $. This is achieved through min-imizing the loss between the reconstructed images $F(Y; \\Theta)$ and the corresponding ground truth high-resolution images $X$. Given a set of high-resolution images $\\{Xi\\}$ and their corresponding low-resolution images $\\{Yi\\}$, we use Mean Squared Error (MSE) as the loss function: \n",
    "\n",
    "\\begin{equation}\n",
    "L(\\Theta) = \\frac{1}{n} \\sum_{i=1}^{n}{{|| F(Y_i,\\Theta) - X_i ||}^2},\n",
    "\\end{equation}\n",
    "where $n$ is the number of training samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code\n",
    "\n",
    "1) Load the image\n",
    "\n",
    "2) preprocess the image\n",
    "\n",
    "3) Load the pretrained model\n",
    "\n",
    "4) Get output from the pretrained model\n",
    "\n",
    "5) Rescale it and ave it with the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named layer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b79669968f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_processing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named layer"
     ]
    }
   ],
   "source": [
    "# Main Packages and Libraries\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle as pickle\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "#from layer import ConvLayer\n",
    "#from tools.image_processing import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The main Function Loop\n",
    "\n",
    "#Loading the image\n",
    "input_img = cv2.imread(photo_file_path, cv2.IMREAD_COLOR)\n",
    "input_image_height = input_img.shape[0]\n",
    "input_image_width = input_img.shape[1]\n",
    "\n",
    "# Output image size\n",
    "output_image_height = 2 * input_image_height\n",
    "output_image_width = 2 * input_image_width\n",
    "\n",
    "# Load the trained model\n",
    "f = open(os.path.join(model_folder, 'train.json'), 'r')\n",
    "model_data = json.load(f)\n",
    "\n",
    "# model parameters\n",
    "rng = np.random.RandomState(model_data[\"rng_seed\"])\n",
    "input_channel_number = model_data[\"input_channel\"]\n",
    "layer_count = model_data[\"layer_count\"]\n",
    "#batch_size = model_data[\"minibatch_size\"]\n",
    "batch_size = 1  # We will convert one photo file\n",
    "layers = model_data[\"layers\"]\n",
    "\n",
    "# WE ARE TAKING SYMMETRICAL FILTERS ONLY\n",
    "# And ofcourse odd number as the filter length\n",
    "image_padding = 0\n",
    "for i in np.arange(layer_count):\n",
    "    image_padding += layers[i][\"filter_height\"] - 1\n",
    "total_image_padding = image_padding\n",
    "## Why is this being done?\n",
    "\n",
    "## Making the theano variables\n",
    "index = T.lscalar()  # index to a minibatch\n",
    "x = T.tensor4(name='x')  # input data (rasterized images): (batch_size, ch, image_height, image_width)\n",
    "y = T.tensor4(name='y')  # output data (rasterized images): (batch_size, ch, image_height, image_width)\n",
    "layer0_input = x # x.reshape((batch_size, input_channel_number, output_image_height, output_image_width))\n",
    "# shape(batch_size, #of feature map, image height, image width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the best trained model from pickled file\n",
    "# Refer Conv layer\n",
    "\n",
    "param_lists = pickle.load(open(os.path.join(model_folder, 'best_model.pkl')))\n",
    "conv_layers = []\n",
    "for i in np.arange(layer_count):\n",
    "    if i == 0:\n",
    "        previous_layer_channel = input_channel_number\n",
    "        layer_input = layer0_input\n",
    "    else:\n",
    "        previous_layer_channel = layers[i-1][\"channel\"]\n",
    "        layer_input = conv_layers[-1].output\n",
    "    layer = ConvLayer(\n",
    "        rng,\n",
    "        input=layer_input,\n",
    "        image_shape=(batch_size, previous_layer_channel, output_image_height + image_padding, output_image_width + image_padding),\n",
    "        filter_shape=(layers[i][\"channel\"], previous_layer_channel, layers[i][\"filter_height\"], layers[i][\"filter_width\"]),\n",
    "        W_values=param_lists[i][0],\n",
    "        b_values=param_lists[i][1]\n",
    "    )\n",
    "    conv_layers.append(layer)\n",
    "    \n",
    "cost = conv_layers[-1].cost(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the read image into YCC format\n",
    "ycc_input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2YCR_CB)\n",
    "data_prescaled_x = np.empty((1, input_channel_number, input_image_height, input_image_width))\n",
    "data_prescaled_x[0, :, :, :] = np.transpose(ycc_input_img[:, :, 0:1], (2, 0, 1))\n",
    "## REFER PREPROCESSING\n",
    "data_scaled_x = preprocess(data_prescaled_x, total_image_padding // 2)\n",
    "input_x = theano.shared(np.asarray(data_scaled_x, dtype=theano.config.floatX), borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Predicting\n",
    "srcnn_photo_predict = theano.function([],conv_layers[-1].output,\n",
    "                                      givens={x: input_x[:]})\n",
    "output_img_y = srcnn_photo_predict()\n",
    "img0 = output_img_y[0].transpose(1, 2, 0) * 256.\n",
    "scaled_input_img = cv2.resize(input_img, (output_image_width, output_image_height))\n",
    "\n",
    "if compare:\n",
    "    cv2.imwrite(conventional_file_path, scaled_input_img)\n",
    "\n",
    "ycc_scaled_input_img = cv2.cvtColor(scaled_input_img, cv2.COLOR_BGR2YCR_CB)\n",
    "ycc_scaled_input_img[:, :, 0:1] = img0  # (width, height, ch)\n",
    "rgb_scaled_img = cv2.cvtColor(ycc_scaled_input_img, cv2.COLOR_YCR_CB2BGR)\n",
    "cv2.imwrite(output_file_path, rgb_scaled_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Code\n",
    "\n",
    "1) Get the size of the conv layer, filter size, number etc\n",
    "\n",
    "2) make loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvLayer(object):\n",
    "    \n",
    "    def __init__(self, rng, input, filter_shape, image_shape, activation=None,\n",
    "             W_values=None, b_values=None,\n",
    "             use_adam=False):\n",
    "        \"\"\"\n",
    "        :param rng: RandomState - random number generator\n",
    "        :param input: dtensor4 (batch_size, #of input feature map, image height, image width)\n",
    "        :param filter_shape: (W is filter) tuple/list of length 4\n",
    "        (#of filters (output feature map), #of input feature map, filter height, filter width)\n",
    "        :param image_shape: tuple/list of length 4 (batch_size, #of input feature map, image height, image width)\n",
    "        :param activation: Not used for now, instead we use LReLU as default\n",
    "        :param W_values: None for initialize with random value (Training phase)\n",
    "                  set numpy.ndarray for specifying W_value (Trained value will be set here in Application phase)\n",
    "                  4D array - (#of filters (output feature map), #of input feature map, filter height, filter width)\n",
    "                  [NOTE] self.W is theano.tensor.shared.var.TensorSharedVariable, but this W is numpy.adarray (only value)\n",
    "        :param b_values: None for initialize with random value (Training phase)\n",
    "                  set numpy.ndarray for specifying W_value (Trained value will be set here in Application phase)\n",
    "                  [NOTE] self.b is theano.tensor.shared.var.TensorSharedVariable, but this b is numpy.adarray (only value)\n",
    "                  1D array - (#of filters (output feature map), )\n",
    "        :param use_adam: deprecated, should be always True. (True when use ADAM)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert image_shape[1] == filter_shape[1]  # make sure they are the same\n",
    "        # pad outside, to maintain input image & output image's height/width same.\n",
    "        self.input = input\n",
    "\n",
    "        #fan_in - #of input to convolution layer = #of input feature maps * filter height * filter width\"\n",
    "        fan_in = np.prod(filter_shape[1:])\n",
    "        #fan_out - #of output which one element affects to = #of output * filter height * filter width\"\n",
    "        fan_out = (filter_shape[0]) * np.prod(filter_shape[2:])\n",
    "\n",
    "        # init @: 4d tensor(filter_shape)\n",
    "        if W_values is None:\n",
    "            # Training phase, init with random value\n",
    "            W_bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "            # W_bound = 1. / fan_in\n",
    "            W_values = np.asarray(\n",
    "                rng.uniform(low=-1.0*W_bound, high=1.2*W_bound, size=filter_shape),\n",
    "                dtype=theano.config.floatX\n",
    "            )\n",
    "\n",
    "        self.W = theano.shared(W_values, borrow=True)\n",
    "        # for the bias\n",
    "        if b_values is None:\n",
    "            # Training phase, init with 0\n",
    "            b_values = np.zeros((filter_shape[0],), dtype=theano.config.floatX)\n",
    "        self.b = theano.shared(value=b_values, borrow=True)\n",
    "\n",
    "        if use_adam:\n",
    "            zero_W_values = np.zeros(filter_shape, dtype=theano.config.floatX)\n",
    "            self.W_m = theano.shared(value=zero_W_values, borrow=False)\n",
    "            self.W_v = theano.shared(value=zero_W_values, borrow=False)\n",
    "            self.b_m = theano.shared(value=b_values, borrow=False)\n",
    "            self.b_v = theano.shared(value=b_values, borrow=False)  # for momentum\n",
    "        # CONVOLUTION\n",
    "        # image_shape: tuple/list of length 4 (batch_size, #of input feature map, image height, image width)\n",
    "        #conv_out: 4d tensor (batch_size, #of output feature map, output height, output width)\n",
    "        conv_out = conv2d(\n",
    "            input=input,\n",
    "            filters=self.W,\n",
    "            filter_shape=filter_shape,\n",
    "            border_mode='valid',\n",
    "            input_shape=image_shape\n",
    "        )\n",
    "        conv_out_plus_b = conv_out + self.b.dimshuffle('x', 0, 'x', 'x')\n",
    "        # TODO: consider activation\n",
    "        # - sigmoid, tanh, LeRU (max(0, x)) etc.\n",
    "\n",
    "        # - relu: vanishing gradient occurs\n",
    "        # self.output = T.minimum(T.maximum(0, conv_out + self.b.dimshuffle('x', 0, 'x', 'x')), 1)\n",
    "\n",
    "        # - lrelu: leak rectified linear unit\n",
    "        # self.output = T.switch(T.lt(conv_out_plus_b, 0), -0.1*conv_out_plus_b, conv_out_plus_b) # LReLU\n",
    "\n",
    "        # - cropped leaky relu -> cropped to 0-1\n",
    "        self.output = T.switch(T.lt(conv_out_plus_b, - 1179 / 256.), 0,\n",
    "                               T.switch(T.lt(conv_out_plus_b, 1 / 256.), conv_out_plus_b / 1280. + 1279 / 327680.,\n",
    "                                        T.switch(T.lt(conv_out_plus_b, 255 / 256.), conv_out_plus_b,\n",
    "                                                 T.switch(T.lt(conv_out_plus_b, 1535 / 256.), conv_out_plus_b / 1280. + 326145. / 327680.,\n",
    "                                                          1))))\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "        if use_adam:\n",
    "            self.params_m = [self.W_m, self.b_m]\n",
    "            self.params_v = [self.W_v, self.b_v]\n",
    "\n",
    "    def cost(self, y):\n",
    "        \"\"\" calculating cost by Mean Squared Error (MSE) as the loss function\n",
    "        NOTE: y and self.output must be same tensor size\n",
    "        :param y: 4d tensor (batch_size, #of feature map (3 for RGB), output height, output width)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return T.mean(T.sqr(y - self.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(pre_scaled_x, image_padding=0):\n",
    "    \"\"\"\n",
    "    preprocessing image consists of 3 parts\n",
    "    1. Scaling: scale original input image to twice scale, using nearest neighbor method.\n",
    "    2. Normalization: normalize each pixel's value from 0~256 to 0~1\n",
    "    3. Padding: pad edge using np.pad.\n",
    "                because image size will reduce during convolution in neural network\n",
    "    :param pre_scaled_x:  original input image (numpy.array)\n",
    "    :param image_padding: value of pixel to be padded\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print('preprocess...')\n",
    "    print('pre_scaled_x.shape', pre_scaled_x.shape)\n",
    "    scaled_x = np.empty((pre_scaled_x.shape[0],\n",
    "                         pre_scaled_x.shape[1],\n",
    "                         pre_scaled_x.shape[2] * 2,\n",
    "                         pre_scaled_x.shape[3] * 2),\n",
    "                        )\n",
    "    # dtype=train_set_x.dtype)\n",
    "    for k in np.arange(pre_scaled_x.shape[2]):\n",
    "        for l in np.arange(pre_scaled_x.shape[3]):\n",
    "            # scaled_x[i][j, 2 * k: 2 * k + 1, 2 * l: 2 * l + 1] = pre_scaled_x[i, j, k, l] / 256.\n",
    "            scaled_x[:, :, 2 * k, 2 * l] = pre_scaled_x[:, :, k, l] / 256.\n",
    "            scaled_x[:, :, 2 * k, 2 * l + 1] = pre_scaled_x[:, :, k, l] / 256.\n",
    "            scaled_x[:, :, 2 * k + 1, 2 * l] = pre_scaled_x[:, :, k, l] / 256.\n",
    "            scaled_x[:, :, 2 * k + 1, 2 * l + 1] = pre_scaled_x[:, :, k, l] / 256.\n",
    "\n",
    "    # print('pre_scaled_x = ', pre_scaled_x)\n",
    "    # print('scaled_x = ', scaled_x)\n",
    "\n",
    "    # PADDING\n",
    "    if image_padding > 0:\n",
    "        print('image padding ', image_padding, ' pixels...')\n",
    "        new_img = np.empty((scaled_x.shape[0], scaled_x.shape[1],\n",
    "                            scaled_x.shape[2] + 2 * image_padding,\n",
    "                            scaled_x.shape[3] + 2 * image_padding), dtype=scaled_x.dtype)\n",
    "        for i in np.arange(scaled_x.shape[0]):\n",
    "            for j in np.arange(scaled_x.shape[1]):\n",
    "                new_img[i, j, :, :] = np.pad(scaled_x[i, j, :, :], image_padding, \"edge\")\n",
    "        scaled_x = new_img\n",
    "\n",
    "    return scaled_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "To build Low res files and high res files from given images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_data(image_save_flag=False):\n",
    "    index = 0\n",
    "    logfile = open(logfile_name, 'w')\n",
    "\n",
    "    if image_save_flag:\n",
    "        if not os.path.exists(cropped_directory):\n",
    "            os.makedirs(cropped_directory)\n",
    "        if not os.path.exists(half_directory):\n",
    "            os.makedirs(half_directory)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        # print root, dirs, files\n",
    "        batch_size = len(files)\n",
    "        print('file size', len(files))\n",
    "        data_x = np.empty((batch_size, image_channel_number, crop_height / 2, crop_width / 2))\n",
    "        data_y = np.empty((batch_size, image_channel_number, crop_height, crop_width))\n",
    "\n",
    "        for file in files:\n",
    "            img = cv2.imread(os.path.join(root, file))\n",
    "\n",
    "            # crop largest square image from center\n",
    "            height = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "            shorter_edge = min(height, width)\n",
    "            if shorter_edge < crop_height:\n",
    "                print('skip', file)\n",
    "                print('skip', file, file=logfile)\n",
    "                continue\n",
    "            # print 'shorter_edge', shorter_edge  # (h, w, 3) = (height, width, channel RGB)  where h == w\n",
    "            # NOTE: its img[y: y + h, x: x + w] and *not* img[x: x + w, y: y + h]\n",
    "            square_img = img[\n",
    "                       height // 2 - shorter_edge // 2: height // 2 + shorter_edge // 2,\n",
    "                       width // 2 - shorter_edge // 2: width // 2 + shorter_edge // 2,\n",
    "                       :]\n",
    "\n",
    "            # print square_img.shape  # (h, w, 3) = (height, width, channel RGB)  where h == w\n",
    "            # crop_img = cv2.resize(square_img, (crop_height, crop_width))\n",
    "            crop_img = img[\n",
    "                       height // 2 - crop_height // 2: height // 2 + crop_height // 2,\n",
    "                       width // 2 - crop_width // 2: width // 2 + crop_width // 2,\n",
    "                       :]\n",
    "\n",
    "            # print crop_img.shape  # (h, w, 3) = (height, width, channel RGB)  where h == w = 256\n",
    "            # save y image\n",
    "            if image_save_flag:\n",
    "                print('saving to ', os.path.join(cropped_directory, file))\n",
    "                cv2.imwrite(os.path.join(cropped_directory, file), crop_img)\n",
    "\n",
    "            # Construct answer data y\n",
    "            # convert from RGB to YCbCr\n",
    "            ycc_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2YCR_CB)\n",
    "            transposed_y_img = np.transpose(crop_img[:, :, 0:1], (2, 0, 1))  # (ch, height, width)\n",
    "\n",
    "            data_y[index, :, :, :] = transposed_y_img\n",
    "            # print transposed_y_img.shape  # (3, 420, 640) = (channel, height, width)\n",
    "\n",
    "            # resize image half. NOTE: size order is (width, height)\n",
    "            half_img = cv2.resize(ycc_img, (crop_width // 2, crop_height // 2))\n",
    "            # print half_img.shape\n",
    "            if image_save_flag:\n",
    "                print('saving to ', os.path.join(half_directory, file))\n",
    "                cv2.imwrite(os.path.join(half_directory, file), half_img)\n",
    "\n",
    "            ycc_half_img = cv2.cvtColor(half_img, cv2.COLOR_BGR2YCR_CB)\n",
    "            transposed_y_half_img = np.transpose(ycc_half_img[:, :, 0:1], (2, 0, 1))  # (ch, height, width)\n",
    "            data_x[index] = transposed_y_half_img\n",
    "            # cv2.imwrite(os.path.join(half_directory, file), half_img)\n",
    "            index += 1\n",
    "\n",
    "        # print 'data_x.shape', data_x.shape\n",
    "        # print 'data_y.shape', data_y.shape\n",
    "        # dataset = (shared_x, shared_y)\n",
    "        dataset = (data_x, data_y)\n",
    "\n",
    "        return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SRCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_srcnn(n_epochs=1000,\n",
    "                  image_height=232,\n",
    "                  image_width=232,\n",
    "                  resume=False):\n",
    "    \"\"\"\n",
    "    :param n_epochs:\n",
    "    :param batch_size: minibatch_size to train\n",
    "    :param image_height:\n",
    "    :param image_width:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_log_file = open(os.path.join(training_model_folder, train_log_file_name), 'w')\n",
    "\n",
    "    # model data loading\n",
    "    f = open(os.path.join(training_model_folder, 'train.json'))\n",
    "    model_data = json.load(f)\n",
    "    rng = np.random.RandomState(model_data[\"rng_seed\"])\n",
    "\n",
    "    # #of feature map = 1 - Y only from YCbCr, you need to modify a bit to support 3 - RGB channel\n",
    "    input_channel_number = model_data[\"input_channel\"]\n",
    "    layer_count = model_data[\"layer_count\"]\n",
    "    batch_size = model_data[\"minibatch_size\"]\n",
    "    layers = model_data[\"layers\"]\n",
    "\n",
    "    image_padding = 0\n",
    "    for i in np.arange(layer_count):\n",
    "        # currently it only supports filter height == filter width\n",
    "        assert layers[i][\"filter_height\"] == layers[i][\"filter_width\"], \"filter height and filter width must be same!\"\n",
    "        assert layers[i][\"filter_height\"] % 2 == 1, \"Only odd number filter is supported!\"\n",
    "        image_padding += layers[i][\"filter_height\"] - 1\n",
    "\n",
    "    total_image_padding = image_padding\n",
    "\n",
    "    # training data loading\n",
    "    datasets = load_data()\n",
    "\n",
    "    np_train_dataset, np_valid_dataset, np_test_dataset = datasets\n",
    "    np_train_set_x, np_train_set_y = np_train_dataset\n",
    "    np_valid_set_x, np_valid_set_y = np_valid_dataset\n",
    "    np_test_set_x, np_test_set_y = np_test_dataset\n",
    "\n",
    "    # print('train_set_x.shape[0]', train_set_x.shape[0].eval())\n",
    "    # PREPROCESSING\n",
    "    start_time = timeit.default_timer()\n",
    "    train_scaled_x = preprocess(np_train_set_x, total_image_padding // 2)\n",
    "    valid_scaled_x = preprocess(np_valid_set_x, total_image_padding // 2)\n",
    "    test_scaled_x = preprocess(np_test_set_x, total_image_padding // 2)\n",
    "    end_time = timeit.default_timer()\n",
    "    print('preprocess time %i sec' % (end_time - start_time))\n",
    "    print('preprocess time %i sec' % (end_time - start_time), file=train_log_file)\n",
    "\n",
    "    # print('scaled_x', scaled_x)\n",
    "\n",
    "    def shared_dataset(data, borrow=True):\n",
    "        shared_data = theano.shared(np.asarray(data, dtype=theano.config.floatX), borrow=borrow)\n",
    "        return shared_data\n",
    "\n",
    "    train_set_x = shared_dataset(train_scaled_x)\n",
    "    valid_set_x = shared_dataset(valid_scaled_x)\n",
    "    test_set_x = shared_dataset(test_scaled_x)\n",
    "    train_set_y = shared_dataset(np_train_set_y / 256.) # normalize\n",
    "    valid_set_y = shared_dataset(np_valid_set_y / 256.)\n",
    "    test_set_y = shared_dataset(np_test_set_y / 256.)\n",
    "\n",
    "    train_set_batch_size = np_train_set_x.shape[0]\n",
    "    n_train_batches = np_train_set_x.shape[0] // batch_size\n",
    "    n_valid_batches = np_valid_set_x.shape[0] // batch_size\n",
    "    n_test_batches = np_test_set_x.shape[0] // batch_size\n",
    "\n",
    "    # SHOW Test images (0~5)\n",
    "    test_img_batch = test_set_x.get_value(borrow=False)[0: 5]  # OK.\n",
    "    for i in np.arange(5):\n",
    "        cv2.imwrite(os.path.join(training_process_folder, 'photo' + str(i) + '_input.jpg'),\n",
    "                    test_img_batch[i].transpose(1, 2, 0) * 256.)\n",
    "\n",
    "    # allocate symbolic variables for the data\n",
    "    index = T.lscalar()  # index to a minibatch\n",
    "    indexes = T.lvector()  # index randomizer\n",
    "    x = T.tensor4(name='x')  # input data (rasterized images): (batch_size, ch, image_height, image_width)\n",
    "    y = T.tensor4(name='y')  # output data (rasterized images): (batch_size, ch, image_height, image_width)\n",
    "\n",
    "    # BUILD MODEL\n",
    "    print('... building the model')\n",
    "    if resume:\n",
    "        param_lists = pickle.load(open(os.path.join(training_model_folder, 'best_model.pkl')))\n",
    "    layer0_input = x.reshape((batch_size,\n",
    "                              input_channel_number,\n",
    "                              image_height + total_image_padding,\n",
    "                              image_width + total_image_padding))  # shape(batch_size, #of feature map, image height, image width)\n",
    "\n",
    "    ConvLayers = []\n",
    "    updates = []\n",
    "\n",
    "    for i in np.arange(layer_count):\n",
    "        if i == 0:\n",
    "            previous_layer_channel = input_channel_number\n",
    "            layer_input = layer0_input\n",
    "        else:\n",
    "            previous_layer_channel = layers[i-1][\"channel\"]\n",
    "            layer_input = ConvLayers[-1].output\n",
    "\n",
    "        #print('[DEBUG], i = %i, layers[i][\"channel\"] = %i, layers[i][\"filter_height\"] = %i, layers[i][\"filter_width\"] = %i' %\n",
    "        #      (i, layers[i][\"channel\"], layers[i][\"filter_height\"], layers[i][\"filter_width\"]))\n",
    "        if resume:\n",
    "            layer = ConvLayer(\n",
    "                rng,\n",
    "                input=layer_input,\n",
    "                image_shape=(batch_size, previous_layer_channel, image_height + image_padding, image_width + image_padding),\n",
    "                filter_shape=(layers[i][\"channel\"], previous_layer_channel, layers[i][\"filter_height\"], layers[i][\"filter_width\"]),\n",
    "                use_adam=True,\n",
    "                W_values=param_lists[i][0],\n",
    "                b_values=param_lists[i][1]\n",
    "            )\n",
    "        else:\n",
    "            layer = ConvLayer(\n",
    "                rng,\n",
    "                input=layer_input,\n",
    "                image_shape=(batch_size, previous_layer_channel, image_height + image_padding, image_width + image_padding),\n",
    "                filter_shape=(layers[i][\"channel\"], previous_layer_channel, layers[i][\"filter_height\"], layers[i][\"filter_width\"]),\n",
    "                use_adam=True\n",
    "            )\n",
    "        ConvLayers.append(layer)\n",
    "        image_padding -= (layers[i][\"filter_height\"] - 1)\n",
    "        # print('[DEBUG] image_padding = ', image_padding)\n",
    "\n",
    "    # crete train model\n",
    "    # alpha = 0.001\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    epsilon = 0.1  # 0.000001\n",
    "    beta1_t = theano.shared(value=np.cast['float32'](0.0), borrow=True)  # Casting float32 is necessary for GPU usage\n",
    "    beta2_t = theano.shared(value=np.cast['float32'](.9), borrow=True)\n",
    "\n",
    "    cost = ConvLayers[-1].cost(y)\n",
    "\n",
    "    updates.append((beta1_t, beta1_t * beta1))\n",
    "    updates.append((beta2_t, beta1_t * beta2))\n",
    "    for i in np.arange(layer_count):\n",
    "        params = ConvLayers[i].params\n",
    "        params_m = ConvLayers[i].params_m # for adam\n",
    "        params_v = ConvLayers[i].params_v # for adam\n",
    "        gparams = T.grad(cost, params)\n",
    "        for param, gparam, param_m, param_v in zip(params, gparams, params_m, params_v):\n",
    "            # Adam\n",
    "            updates.append((param_m, beta1 * param_m + (1 - beta1) * gparam))\n",
    "            updates.append((param_v, beta2 * param_v + (1 - beta2) * gparam * gparam))\n",
    "            updates.append((param, param - layers[i][\"learning_rate\"] * param_m / (1. - beta1_t) / (T.sqrt(param_v / (1 - beta2_t)) + epsilon)))\n",
    "            # Normal SGD\n",
    "            # updates.append((param, param - layers[i][\"learning_rate\"] * gparam))\n",
    "\n",
    "    # indexes is used for image sequence randomizer for training\n",
    "    train_model = theano.function(\n",
    "        [index, indexes],\n",
    "        cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[indexes[index * batch_size: (index + 1) * batch_size]],\n",
    "            y: train_set_y[indexes[index * batch_size: (index + 1) * batch_size]]\n",
    "        }\n",
    "    )\n",
    "    # create a test function\n",
    "    # TODO: implement error function (test evaluation function, e.g. PSNR), instead of using cost function\n",
    "    test_model = theano.function(\n",
    "        [index],\n",
    "        ConvLayers[-1].cost(y),\n",
    "        givens={\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: test_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    validate_model = theano.function(\n",
    "        [index],\n",
    "        ConvLayers[-1].cost(y),\n",
    "        givens={\n",
    "            x: valid_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: valid_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    construct_photo = theano.function(\n",
    "        [index],\n",
    "        ConvLayers[-1].output,\n",
    "        givens={\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # TRAIN MODEL\n",
    "    print('... training')\n",
    "    patience = 30000  # 10000\n",
    "    patience_increase = 2\n",
    "    improvement_threshold = 0.998  # 0.995\n",
    "\n",
    "    validation_frequency = min(n_train_batches, patience // 2) * 2\n",
    "\n",
    "    best_validation_loss = np.inf\n",
    "    best_iter = 0\n",
    "    test_score = 0.\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    epoch = 0\n",
    "    done_looping = False\n",
    "\n",
    "    while (epoch < n_epochs) and (not done_looping):\n",
    "        start_time_for_each_epoch = timeit.default_timer()\n",
    "        epoch += 1\n",
    "        mean_cost = []\n",
    "        random_indexes = np.random.permutation(train_set_batch_size)  # index randomizer\n",
    "        for minibatch_index in range(n_train_batches):\n",
    "            iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "\n",
    "            if iter < 10:\n",
    "                img_batch = construct_photo(0)\n",
    "                img0 = img_batch[0].transpose(1, 2, 0) * 256.\n",
    "                print('[DEBUG] iter ', iter, ' img0: ', img0)\n",
    "\n",
    "            if iter % 100 == 0:\n",
    "                print('training @ iter ', iter)\n",
    "            mean_cost += [train_model(minibatch_index, random_indexes)]\n",
    "\n",
    "            if (iter + 1) % validation_frequency == 0:\n",
    "                validation_losses = [validate_model(i) for i in range(n_valid_batches)]\n",
    "                this_validation_loss = np.mean(validation_losses)\n",
    "                print('epoch %i, minibatch %i/%i, validation cost %f' %\n",
    "                      (epoch, minibatch_index + 1, n_train_batches, this_validation_loss))\n",
    "                print('epoch %i, minibatch %i/%i, validation cost %f' %\n",
    "                      (epoch, minibatch_index + 1, n_train_batches, this_validation_loss),\n",
    "                      file=train_log_file)\n",
    "\n",
    "                if this_validation_loss < best_validation_loss:\n",
    "                    if this_validation_loss < best_validation_loss * improvement_threshold:\n",
    "                        patience = max(patience, iter * patience_increase)\n",
    "                        print('update patience -> ', patience, ' iter')\n",
    "                        # we will execute at least patience iter.\n",
    "\n",
    "                    best_validation_loss = this_validation_loss\n",
    "                    best_iter = iter\n",
    "\n",
    "                    test_losses = [test_model(i) for i in range(n_test_batches)]\n",
    "                    test_score = np.mean(test_losses)\n",
    "                    print('     epoch %i, minibatch %i/%i, test cost of best model %f' %\n",
    "                          (epoch, minibatch_index + 1, n_train_batches, test_score))\n",
    "                    print('     epoch %i, minibatch %i/%i, test cost of best model %f' %\n",
    "                          (epoch, minibatch_index + 1, n_train_batches, test_score),\n",
    "                          file=train_log_file)\n",
    "                    # Save best model\n",
    "                    with open(os.path.join(training_model_folder, 'best_model.pkl'), 'wb') as f:\n",
    "                        param_lists = []\n",
    "                        for i in np.arange(layer_count):\n",
    "                            param_lists.append([ConvLayers[i].W.get_value(), ConvLayers[i].b.get_value()])\n",
    "                        pickle.dump(param_lists, f)\n",
    "\n",
    "            if patience <= iter:\n",
    "                done_looping = True\n",
    "                break\n",
    "        end_time_for_each_epoch = timeit.default_timer()\n",
    "        diff_time = end_time_for_each_epoch - start_time_for_each_epoch\n",
    "        print('Training epoch %d cost is %f, took %i min %i sec' %\n",
    "              (epoch, np.mean(mean_cost), diff_time / 60., diff_time % 60))\n",
    "        print('Training epoch %d cost is %f, took %i min %i sec' %\n",
    "              (epoch, np.mean(mean_cost), diff_time / 60., diff_time % 60),\n",
    "              file=train_log_file)\n",
    "\n",
    "        # for checking/monitoring the training process\n",
    "        if epoch // 10 == 0 or epoch % 10 == 0:\n",
    "            photo_num = 0\n",
    "            loop = 0\n",
    "            while photo_num < 5:\n",
    "                img_batch = construct_photo(loop)\n",
    "                for j in np.arange(batch_size):\n",
    "                    if photo_num == 0:\n",
    "                        print('output_img0: ', img_batch[j].transpose(1, 2, 0) * 256.)\n",
    "                    cv2.imwrite(os.path.join(training_process_folder,\n",
    "                                             'photo' + str(photo_num) + '_epoch' + str(epoch) + '.jpg'),\n",
    "                                img_batch[j].transpose(1, 2, 0) * 256.)\n",
    "                    photo_num += 1\n",
    "                    if photo_num == 5:\n",
    "                        break\n",
    "                loop += 1\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "\n",
    "    print('Optimization complete.')\n",
    "    print('Best validation score of %f %% obtained at iteration %i, '\n",
    "          'with test performance %f' %\n",
    "          (best_validation_loss, best_iter + 1, test_score))\n",
    "    print(('The code for file ' +\n",
    "           os.path.split(__file__)[1] +\n",
    "           ' ran for %.2fm' % ((end_time - start_time) / 60.)), file=sys.stderr)\n",
    "\n",
    "    print('Optimization complete.',\n",
    "          file=train_log_file)\n",
    "    print('Best validation score of %f obtained at iteration %i, '\n",
    "          'with test performance %f' %\n",
    "          (best_validation_loss, best_iter + 1, test_score),\n",
    "          file=train_log_file)\n",
    "    print(('The code for file ' +\n",
    "           os.path.split(__file__)[1] +\n",
    "           ' ran for %.2fm' % ((end_time - start_time) / 60.)),\n",
    "          file=train_log_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_test_set(image_height=232,\n",
    "                     image_width=232,\n",
    "                     model_folder=training_model_folder):\n",
    "    print('predict...')\n",
    "    if not os.path.exists(model_folder):\n",
    "        print('os.getcwd() ', os.getcwd())\n",
    "        print(model_folder + ' does not exist!')\n",
    "        return\n",
    "\n",
    "    training_process_folder = os.path.join(model_folder, 'training_process')\n",
    "    f = open(os.path.join(model_folder, 'train.json'), 'r')\n",
    "    model_data = json.load(f)\n",
    "\n",
    "    rng = np.random.RandomState(model_data[\"rng_seed\"])\n",
    "    input_channel_number = model_data[\"input_channel\"]\n",
    "    layer_count = model_data[\"layer_count\"]\n",
    "    batch_size = model_data[\"minibatch_size\"]\n",
    "    layers = model_data[\"layers\"]\n",
    "\n",
    "    image_padding = 0\n",
    "    for i in np.arange(layer_count):\n",
    "        # currently it only supports filter height == filter width\n",
    "        assert layers[i][\"filter_height\"] == layers[i][\"filter_width\"], \"filter height and filter width must be same!\"\n",
    "        assert layers[i][\"filter_height\"] % 2 == 1, \"Only odd number filter is supported!\"\n",
    "        image_padding += layers[i][\"filter_height\"] - 1\n",
    "\n",
    "    total_image_padding = image_padding\n",
    "\n",
    "    index = T.lscalar()  # index to a minibatch\n",
    "    x = T.tensor4(name='x')  # input data (rasterized images): (batch_size, ch, image_height, image_width)\n",
    "    y = T.tensor4(name='y')  # output data (rasterized images): (batch_size, ch, image_height, image_width)\n",
    "    layer0_input = x # x.reshape((batch_size, input_channel_number, image_height, image_width))  # shape(batch_size, #of feature map, image height, image width)\n",
    "\n",
    "    param_lists = pickle.load(open(os.path.join(model_folder, 'best_model.pkl')))\n",
    "    #print('param_lists', param_lists)\n",
    "    #print('param_lists1', param_lists[1])\n",
    "    ConvLayers = []\n",
    "\n",
    "    for i in np.arange(layer_count):\n",
    "        if i == 0:\n",
    "            previous_layer_channel = input_channel_number\n",
    "            layer_input = layer0_input\n",
    "        else:\n",
    "            previous_layer_channel = layers[i-1][\"channel\"]\n",
    "            layer_input = ConvLayers[-1].output\n",
    "\n",
    "        layer = ConvLayer(\n",
    "            rng,\n",
    "            input=layer_input,\n",
    "            image_shape=(batch_size, previous_layer_channel, image_height + image_padding, image_width + image_padding),\n",
    "            filter_shape=(layers[i][\"channel\"], previous_layer_channel, layers[i][\"filter_height\"], layers[i][\"filter_width\"]),\n",
    "            W_values=param_lists[i][0],\n",
    "            b_values=param_lists[i][1]\n",
    "        )\n",
    "        #print('layer.W', layer.W, layer.W.get_value())\n",
    "        #print('layer.b', layer.b, layer.b.get_value())\n",
    "        ConvLayers.append(layer)\n",
    "\n",
    "    #print('ConvLayers', ConvLayers)\n",
    "    # crete train model\n",
    "    cost = ConvLayers[-1].cost(y)\n",
    "\n",
    "    datasets = load_data()\n",
    "    train_dataset, valid_dataset, test_dataset = datasets\n",
    "    # train_set_x, train_set_y = train_dataset\n",
    "    # valid_set_x, valid_set_y = valid_dataset\n",
    "    np_test_set_x, np_test_set_y = test_dataset\n",
    "\n",
    "    # PREPROCESSING\n",
    "    test_scaled_x = preprocess(np_test_set_x, total_image_padding // 2)\n",
    "    test_set_x = theano.shared(np.asarray(test_scaled_x, dtype=theano.config.floatX), borrow=True)\n",
    "    #print('test_scaled_x', test_scaled_x)\n",
    "\n",
    "    construct_photo_predict = theano.function(\n",
    "        [index],\n",
    "        ConvLayers[-1].output,\n",
    "        givens={\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    photo_num = 0\n",
    "    loop = 0\n",
    "    while photo_num < 5:\n",
    "        img_batch = construct_photo_predict(loop)\n",
    "        for j in np.arange(batch_size):\n",
    "            if photo_num == 0:\n",
    "                print('output_img0: ', img_batch[j].transpose(1, 2, 0) * 256.)\n",
    "            cv2.imwrite(os.path.join(training_process_folder,\n",
    "                                     'photo' + str(photo_num) + '_predict.jpg'),\n",
    "                        img_batch[j].transpose(1, 2, 0) * 256.)\n",
    "            photo_num += 1\n",
    "            if photo_num == 5:\n",
    "                break\n",
    "        loop += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
